import requests
import time
import telegram
import os
# from bs4 import BeautifulSoup  # Unused
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
import multiprocessing
import io
from datetime import datetime, date  # Import date
import asyncio
import schedule
import re
import random
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry
from requests.packages.urllib3.exceptions import InsecureRequestWarning
import pycountry  # Unused, but good to keep



# --- C·∫§U H√åNH ---
TELEGRAM_BOT_TOKEN = '7582640219:AAHzedxZ8WvFQ9CUU4mXiXw3KFVSZLU8Oi8'  # Thay b·∫±ng token c·ªßa b·∫°n
TELEGRAM_CHAT_ID = '-1002318241724'
ADMIN_TELEGRAM_CHAT_ID = '5929440805'  # Optional
CHECK_TIMEOUT = 3
FETCH_TIMEOUT = 5
SCHEDULE_INTERVAL_MINUTES = 60
# MAX_THREADS = multiprocessing.cpu_count() * 200  # Use this in production
MAX_THREADS = 300  # For debugging, keep it lower
MAX_PROXIES_PER_SOURCE = 100
CONNECT_TIMEOUT = 3
DB_IP_API_KEYS = [
    "ac89ee53b354d9ddded0b84878a23cca289856fc",  # Thay b·∫±ng API key(s) c·ªßa b·∫°n
#    "another_api_key",  # Th√™m c√°c key kh√°c n·∫øu c√≥
]
DB_IP_TIMEOUT = 3


# --- Danh s√°ch URL ki·ªÉm tra ---
CHECK_URLS_HTTP = [
    "http://httpbin.org/get",
    "http://httpbin.org/ip",
]
CHECK_URLS_HTTPS = [
    "https://www.google.com",
    "https://bing.com",
]

# --- Danh s√°ch ngu·ªìn proxy ---
PROXY_SOURCES = [
    {
        "url": "https://proxylist.geonode.com/api/proxy-list?protocols=http&google=false&limit=500&page=1&sort_by=lastChecked&sort_type=desc",
        "type": "http",
        "format": "json"
    },
    {
        "url": "https://proxylist.geonode.com/api/proxy-list?protocols=https&google=false&limit=500&page=1&sort_by=lastChecked&sort_type=desc",
        "type": "https",
        "format": "json"
    },
    {
        "url": "https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&protocol=http&proxy_format=ipport&format=text&timeout=3000",
        "type": "http",
        "format": "text"
    },
    {
        "url": "https://api.proxyscrape.com/v4/free-proxy-list/get?request=display_proxies&protocol=https&proxy_format=ipport&format=text&timeout=3000",
        "type": "https",
        "format": "text"
    }
]

# --- C√ÅC H√ÄM ---

def generate_random_ua():
    """T·∫°o User-Agent ng·∫´u nhi√™n."""
    chrome_version = f"{random.randint(90, 116)}.0.{random.randint(4000, 5000)}.{random.randint(100, 200)}"
    os_versions = {
        "Windows NT 10.0; Win64; x64": 0.7,
        "Macintosh; Intel Mac OS X 10_15_7": 0.2,
        "X11; Linux x86_64": 0.1
    }
    os_choice = random.choices(list(os_versions.keys()), weights=list(os_versions.values()))[0]

    templates = [
        f"Mozilla/5.0 ({os_choice}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_version} Safari/537.36",
        f"Mozilla/5.0 ({os_choice}) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_version} Safari/537.36 Edg/{chrome_version}",  # Edge
    ]
    if "Windows" in os_choice:
        templates.append(
            f"Mozilla/5.0 ({os_choice}; rv:{random.randint(80, 102)}.0) Gecko/20100101 Firefox/{random.randint(80, 102)}.0"
        )

    return random.choice(templates)


async def init_bot():
    """Kh·ªüi t·∫°o bot Telegram."""
    try:
        bot = telegram.Bot(token=TELEGRAM_BOT_TOKEN)
        bot_info = await bot.get_me()
        print(f"Telegram Bot: {bot_info.username} (ID: {bot_info.id})")
        return bot
    except telegram.error.TelegramError as e:
        print(f"L·ªói kh·ªüi t·∫°o Telegram Bot: {e}")
        return None


# T·∫°o session ·ªü ƒë√¢y (global)
session = requests.Session()
retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[500, 502, 503, 504])
adapter = HTTPAdapter(max_retries=retries)
session.mount('http://', adapter)
session.mount('https://', adapter)
requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)


def make_request(url, proxies=None, timeout=None, headers=None):
    """Th·ª±c hi·ªán request, tr·∫£ v·ªÅ None n·∫øu l·ªói."""
    try:
        headers = headers or {}
        headers['User-Agent'] = generate_random_ua()

        # S·ª≠ d·ª•ng session ƒë√£ t·∫°o
        if "rootjazz.com" in url.lower():
            session.verify = False  # T·∫Øt ki·ªÉm tra SSL cho rootjazz.com
        else:
            session.verify = True  # B·∫≠t ki·ªÉm tra SSL (m·∫∑c ƒë·ªãnh)

        response = session.get(url, proxies=proxies, timeout=timeout, headers=headers)
        response.raise_for_status()
        return response

    except requests.exceptions.RequestException as e:
        return None


def get_short_url(url):
    """R√∫t g·ªçn URL."""
    try:
        scheme, rest = url.split("://", 1)
        domain = rest.split("/", 1)[0]
        return f"{scheme}://{domain}"
    except:
        return url


def format_proxy_error(error_message, proxy):
    """
    Ph√¢n t√≠ch v√† ƒë·ªãnh d·∫°ng th√¥ng b√°o l·ªói, tr·∫£ v·ªÅ m√£ tr·∫°ng th√°i.
    """
    # ∆Øu ti√™n l·∫•y status_code n·∫øu c√≥ (ph·∫£n h·ªìi t·ª´ server)
    match_status = re.search(r"HTTPError\((\d+)", error_message)
    if match_status:
        status_code = int(match_status.group(1))
        return f"CHECK PROXY: {proxy} - L·ªñI: {status_code}"

    # N·∫øu kh√¥ng c√≥, ki·ªÉm tra ConnectTimeout
    match_timeout = re.search(r"ConnectTimeoutError", error_message)
    if match_timeout:
        return f"CHECK PROXY: {proxy} - L·ªñI: 0 (Connect Timeout)"

    # N·∫øu kh√¥ng c√≥, ki·ªÉm tra l·ªói ProxyError chung (kh√¥ng c√≥ timeout)
    match_proxy_error = re.search(r"ProxyError", error_message)
    if match_proxy_error:
        return f"CHECK PROXY: {proxy} - L·ªñI: (Proxy Error)"

    return None  # Kh√¥ng kh·ªõp v·ªõi pattern n√†o


def get_country_flag(country_code):
    """L·∫•y emoji c·ªù qu·ªëc gia t·ª´ m√£ qu·ªëc gia."""
    try:
        if country_code and len(country_code) == 2:
            return "".join([chr(ord('üá¶') + ord(c) - ord('A')) for c in country_code.upper()])
        return ""  # Tr·∫£ v·ªÅ chu·ªói r·ªóng n·∫øu kh√¥ng t√¨m th·∫•y
    except Exception:
        return ""

def get_ip_info(ip_address, api_keys):
    """L·∫•y th√¥ng tin IP t·ª´ db-ip.com, s·ª≠ d·ª•ng danh s√°ch API key."""
    api_key = random.choice(api_keys)  # Ch·ªçn ng·∫´u nhi√™n m·ªôt API key
    try:
        url = f"http://api.db-ip.com/v2/{api_key}/{ip_address}"
        response = make_request(url, timeout=DB_IP_TIMEOUT)  # Th√™m timeout
        if response:
            data = response.json()
            # Ki·ªÉm tra l·ªói t·ª´ API
            if 'error' in data:
                print(f"db-ip.com API Error: {data.get('error')}")
                return None, None, None

            country_code = data.get('countryCode')
            country_name = data.get('countryName') # L·∫•y t√™n qu·ªëc gia
            return ip_address, country_code, country_name
        else:
            print(f"L·ªói khi truy v·∫•n db-ip.com cho IP: {ip_address}")
            return None, None, None
    except Exception as e:
        print(f"L·ªói khi truy v·∫•n db-ip.com cho IP: {ip_address}: {e}")
        return None, None, None

def get_api_key_info(api_key):
    """L·∫•y th√¥ng tin chi ti·∫øt c·ªßa m·ªôt API key t·ª´ db-ip.com."""
    try:
        url = f"http://api.db-ip.com/v2/{api_key}"  # Kh√¥ng c·∫ßn IP address
        response = make_request(url, timeout=DB_IP_TIMEOUT)
        if response:
            data = response.json()
            if 'error' in data:
                print(f"db-ip.com API Error: {data.get('error')}")
                return None
            # Th√™m expires (gi·∫£ ƒë·ªãnh l√† kh√¥ng c√≥, b·∫°n c·∫ßn t·ª± th√™m)
            data['expires'] = 'N/A'  # Placeholder
            return data
        else:
            print(f"L·ªói khi truy v·∫•n th√¥ng tin API key: {api_key}")
            return None
    except Exception as e:
        print(f"L·ªói khi truy v·∫•n th√¥ng tin API key: {api_key}: {e}")
        return None


def determine_proxy_type(proxy, connect_timeout, check_timeout):
    """
    X√°c ƒë·ªãnh lo·∫°i proxy v√† th√¥ng tin qu·ªëc gia.
    """
    ip_address, _ = proxy.split(":")  # T√°ch IP

    # Ki·ªÉm tra IP v√† l·∫•y th√¥ng tin qu·ªëc gia *tr∆∞·ªõc* khi ki·ªÉm tra proxy
    ip, country_code, country_name = get_ip_info(ip_address, DB_IP_API_KEYS)
    if not ip or not country_code:
        return None, None, None

    def check_single_proxy(proxy_type, check_urls):
        proxies = {
            'http': f'{proxy_type}://{proxy}',
            'https': f'{proxy_type}://{proxy}'
        }
        for check_url in check_urls:
            try:
                response = make_request(check_url, proxies=proxies, timeout=(connect_timeout, check_timeout),
                                        headers={'User-Agent': generate_random_ua()})
                if response:
                    return True
            except requests.exceptions.RequestException as e:
                formatted_error = format_proxy_error(str(e), proxy)
                if formatted_error:
                    print(formatted_error)
                return False
        return False

    proxy_types = []  # L∆∞u tr·ªØ c√°c lo·∫°i proxy ho·∫°t ƒë·ªông
    # Ki·ªÉm tra HTTP
    if check_single_proxy("http", CHECK_URLS_HTTP):
        proxy_types.append("http")
        # N·∫øu HTTP ho·∫°t ƒë·ªông, ki·ªÉm tra HTTPS
        if check_single_proxy("https", CHECK_URLS_HTTPS):
            proxy_types.append("https")

    if proxy_types:
      return proxy_types, country_code, country_name  # Tr·∫£ v·ªÅ danh s√°ch c√°c lo·∫°i
    else:
      return None, None, None

def fetch_proxies_from_url(source):
    """L·∫•y proxy t·ª´ URL."""
    url = source['url']
    proxy_type = source['type']
    data_format = source.get('format', 'text')
    all_proxies = []
    seen_proxies = set()
    total_fetched_from_this_source = 0
    short_url = get_short_url(url)

    try:
        if data_format == 'json' and "geonode" in url.lower():
            page = 1
            max_pages = 30
            while True:
                paginated_url = re.sub(r"page=\d+", f"page={page}", url)
                response = make_request(paginated_url, timeout=FETCH_TIMEOUT)

                if not response:
                    print(f"L·ªói khi l·∫•y d·ªØ li·ªáu t·ª´ {short_url} (page {page})")
                    break

                try:
                    json_response = response.json()
                    if not isinstance(json_response, dict) or 'data' not in json_response or not isinstance(
                            json_response['data'], list):
                        print(f"D·ªØ li·ªáu JSON kh√¥ng h·ª£p l·ªá t·ª´ {short_url} (page {page})")
                        break

                    proxy_list_page = json_response['data']
                    if not proxy_list_page:
                        print(f"Kh√¥ng c√≥ proxy ·ªü trang {page} t·ª´ {short_url}.")
                        break

                    for proxy_item in proxy_list_page:
                        if 'ip' in proxy_item and 'port' in proxy_item:
                            proxy_string = f"{proxy_item['ip']}:{proxy_item['port']}"
                            if proxy_string not in seen_proxies:
                                all_proxies.append((proxy_string, proxy_type))
                                seen_proxies.add(proxy_string)
                                total_fetched_from_this_source += 1

                    if len(proxy_list_page) < 500:
                        break
                    page += 1
                    if page > max_pages:
                        break
                except (ValueError, KeyError) as e:
                    print(f"L·ªói khi x·ª≠ l√Ω JSON t·ª´ {short_url} (page {page}): {e}")
                    break

        elif data_format == 'text':
            if "github.com" in url:
                if url.startswith("github.com"):
                    url = "www." + url
                # Regex cho c·∫£ hai ƒë·ªãnh d·∫°ng GitHub
                url = re.sub(r"(www\.)?github\.com/([^/]+)/([^/]+)/(blob|tree|refs/heads)/([^/]+)/",
                             r"raw.githubusercontent.com/\2/\3/\5/", url)

            response = make_request(url, timeout=FETCH_TIMEOUT)
            if not response:
                print(f"L·ªói khi l·∫•y d·ªØ li·ªáu t·ª´ {short_url}")
                return []

            response.encoding = 'utf-8'
            for line in response.text.splitlines():
                line = line.strip()
                line = re.sub(r"^(http:\/\/|https:\/\/)", "", line)

                ip_port_match = re.search(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5}', line)
                if ip_port_match:
                    extracted_proxy = ip_port_match.group(0)
                    if re.match(r'^\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{1,5}$', extracted_proxy):
                        if extracted_proxy not in seen_proxies:
                            if proxy_type:
                                all_proxies.append((extracted_proxy, proxy_type))
                            else:
                                all_proxies.append((extracted_proxy, 'http'))
                                all_proxies.append((extracted_proxy, 'https'))
                            seen_proxies.add(extracted_proxy)
                            total_fetched_from_this_source += 1

        else:
            print(f"ƒê·ªãnh d·∫°ng kh√¥ng h·ªó tr·ª£: {data_format} for URL {short_url}")
            return []

        if total_fetched_from_this_source > MAX_PROXIES_PER_SOURCE:
            print(f"ƒê√£ l·∫•y h∆°n {MAX_PROXIES_PER_SOURCE} proxy t·ª´ {short_url}. B·ªè qua.")
            return []

        print(f"ƒê√£ l·∫•y ƒë∆∞·ª£c {total_fetched_from_this_source} proxy t·ª´ {short_url}")
        return all_proxies

    except Exception as e:
        print(f"L·ªói khi l·∫•y ho·∫∑c x·ª≠ l√Ω proxy t·ª´ {short_url}: {e}")
        return []


def process_proxies():
    """L·∫•y, ki·ªÉm tra v√† tr·∫£ v·ªÅ proxy live."""
    print("--- B·∫Øt ƒë·∫ßu x·ª≠ l√Ω proxy ---")
    combined_proxies_to_check = []
    failed_urls = []

    for source in PROXY_SOURCES:
        try:
            proxies = fetch_proxies_from_url(source)
            if proxies is not None:
                combined_proxies_to_check.extend(proxies)
            else:
                failed_urls.append(get_short_url(source["url"]))
        except Exception as e:
            print(f"L·ªói khi l·∫•y proxy t·ª´ {get_short_url(source['url'])}: {e}")
            failed_urls.append(get_short_url(source["url"]))

    live_proxies_lists = {'http': [], 'https': []}
    live_proxies_count = {'http': 0, 'https': 0}
    # L∆∞u tr·ªØ th√¥ng tin qu·ªëc gia v√† s·ªë l∆∞·ª£ng theo qu·ªëc gia
    proxy_info = {}  # D·∫°ng: {proxy: (type, country_code, country_name)}
    country_counts = {}

    if not CHECK_URLS_HTTP and not CHECK_URLS_HTTPS:
        print("Kh√¥ng c√≥ URL ki·ªÉm tra.")
        return live_proxies_lists, live_proxies_count, failed_urls, proxy_info, country_counts

    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:
        futures = [
            executor.submit(determine_proxy_type, proxy, CONNECT_TIMEOUT, CHECK_TIMEOUT)
            for proxy, _ in combined_proxies_to_check
        ]

        for future in as_completed(futures):
            proxy_index = futures.index(future)
            proxy, proxy_type_expected = combined_proxies_to_check[proxy_index]
            try:
                proxy_types, country_code, country_name = future.result()  # Ch√∫ √Ω: proxy_types l√† m·ªôt list
                if proxy_types:
                    for proxy_type in proxy_types:  # Duy·ªát qua danh s√°ch c√°c lo·∫°i proxy
                        live_proxies_lists[proxy_type].append(proxy)
                        live_proxies_count[proxy_type] += 1
                        # L∆∞u th√¥ng tin (ch·ªâ l∆∞u m·ªôt l·∫ßn, v·ªõi lo·∫°i ƒë·∫ßu ti√™n)
                        if proxy not in proxy_info:
                            proxy_info[proxy] = (proxy_type, country_code, country_name)
                    # C·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng qu·ªëc gia
                    if country_code:
                         country_counts[country_code] = country_counts.get(country_code, 0) + 1

                    print(f"IP: {proxy} ({country_name}) - {', '.join(proxy_types).upper()}") # In ra c√°c lo·∫°i

            except Exception as e:
                # print(f"L·ªói khi ki·ªÉm tra proxy {proxy}: {e}")  # ƒê√£ x·ª≠ l√Ω trong determine_proxy_type
                pass
    print("--- Ho√†n t·∫•t x·ª≠ l√Ω proxy ---")
    return live_proxies_lists, live_proxies_count, failed_urls, proxy_info, country_counts


async def upload_to_telegram(bot, live_proxies_lists, live_proxies_count, failed_urls, proxy_info, country_counts, api_keys_info):
    """T·∫£i proxy l√™n Telegram, v·ªõi ƒë·ªãnh d·∫°ng m·ªõi, bao g·ªìm th√¥ng tin API."""
    print("--- B·∫Øt ƒë·∫ßu upload l√™n Telegram ---")
    try:
        # --- T·∫°o th√¥ng b√°o API ---
        api_message = "‚ú®Ô∏è TOTAL API LIMIT 1/DAY ‚ú®Ô∏è\n\n"

        for i, api_key_data in enumerate(api_keys_info):
            status = api_key_data.get('status', 'Unknown')
            status = status.lower()  # Chuy·ªÉn v·ªÅ ch·ªØ th∆∞·ªùng ƒë·ªÉ so s√°nh

            # Th√™m icon d·ª±a tr√™n tr·∫°ng th√°i
            if status in ("trial", "active"):
                status_icon = "‚úÖÔ∏è"
            elif status == "canceled":
                status_icon = "‚ùåÔ∏è"
            else:
                status_icon = "‚ùìÔ∏è"

            api_message += f"{status_icon} STATUS: {status.upper()}\n"  # Icon + STATUS vi·∫øt hoa
            queries_left = api_key_data.get('queriesLeft', 'N/A')
            expires = api_key_data.get('expires', 'N/A')  # V·∫´n gi·ªØ tr∆∞·ªùng expires, d√π gi√° tr·ªã l√† N/A
            api_message += f"‚ö°Ô∏èAPI {i+1}: {queries_left} REQUEST | EXPIRES: {expires}\n"

        # --- T·∫°o th√¥ng b√°o ch√≠nh (Proxy) ---
        message = api_message + "\n" + "üìä PROXY LIVE (HTTP/HTTPS) üìä\n\n"
        message += f"- HTTP: {live_proxies_count['http']} PROXY\n"
        message += f"- HTTPS: {live_proxies_count['https']} PROXY\n"
        message += "\nüåê LIST OF PROXY COUNTRY üåê\n\n"

        # Th√™m th·ªëng k√™ qu·ªëc gia
        country_list = []
        for code, count in country_counts.items():
            name = "Unknown"  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
            # T√¨m t√™n qu·ªëc gia (duy·ªát qua proxy_info ƒë·ªÉ t√¨m, t·ªëi ∆∞u h∆°n)
            for _, info in proxy_info.items():
                if info[1] == code:
                    name = info[2]
                    break
            flag = get_country_flag(code)
            country_list.append(f"{flag} {name}: {count}")

        # Chia danh s√°ch qu·ªëc gia th√†nh c√°c nh√≥m (m·ªói nh√≥m 3 ph·∫ßn t·ª≠)
        n = 3
        grouped_countries = [country_list[i:i + n] for i in range(0, len(country_list), n)]
        message += " | ".join(grouped_countries[0])  # D√≤ng ƒë·∫ßu ti√™n
        for group in grouped_countries[1:]:
            message += "\n" + " | ".join(group)  # C√°c d√≤ng ti·∫øp theo (xu·ªëng d√≤ng)

        total_proxies = sum(live_proxies_count.values())
        message += f"\n\nüî• TOTAL PROXY LIVE: {total_proxies} üî•\n"

        if failed_urls:
            message += "\n\n‚ö†Ô∏è C√°c URL sau b·ªã l·ªói:\n"
            for url in failed_urls:
                message += f"- {url}\n"

        # --- G·ª≠i tin nh·∫Øn vƒÉn b·∫£n ---
        await bot.send_message(chat_id=TELEGRAM_CHAT_ID, text=message)

        # --- Upload file HTTP (n·∫øu c√≥) ---
        if live_proxies_lists['http']:
            http_proxy_list_string = "\n".join(live_proxies_lists['http'])
            http_proxy_file = io.StringIO(http_proxy_list_string)
            http_proxy_file.name = "HTTP_LIVE.txt"
            await bot.send_document(chat_id=TELEGRAM_CHAT_ID, document=http_proxy_file,
                                    caption=f"üì¶ HTTP PROXY LIVE ({live_proxies_count['http']})")
            print("ƒê√£ upload file HTTP l√™n Telegram.")
        else:
            print("Kh√¥ng c√≥ proxy HTTP live.")

        # --- Upload file HTTPS (n·∫øu c√≥) ---
        if live_proxies_lists['https']:
            https_proxy_list_string = "\n".join(live_proxies_lists['https'])
            https_proxy_file = io.StringIO(https_proxy_list_string)
            https_proxy_file.name = "HTTPS_LIVE.txt"
            await bot.send_document(chat_id=TELEGRAM_CHAT_ID, document=https_proxy_file,
                                    caption=f"üì¶ HTTPS PROXY LIVE ({live_proxies_count['https']})")
            print("ƒê√£ upload file HTTPS l√™n Telegram.")
        else:
            print("Kh√¥ng c√≥ proxy HTTPS live.")

    except telegram.error.TelegramError as e:
        print(f"L·ªói Telegram: {e}")  # X·ª≠ l√Ω l·ªói Telegram c·ª• th·ªÉ
        # C√≥ th·ªÉ g·ª≠i th√¥ng b√°o l·ªói l√™n Telegram cho admin
        if bot and ADMIN_TELEGRAM_CHAT_ID:
            await send_admin_notification(bot, f"L·ªói Telegram trong upload_to_telegram: {e}")
    except Exception as e:
        print(f"L·ªói chung trong upload_to_telegram: {e}")  # X·ª≠ l√Ω c√°c l·ªói kh√°c
        if bot and ADMIN_TELEGRAM_CHAT_ID:
              await send_admin_notification(bot, f"L·ªói trong upload_to_telegram: {e}")

async def send_admin_notification(bot, message):
    """G·ª≠i th√¥ng b√°o cho admin."""
    if ADMIN_TELEGRAM_CHAT_ID:
        try:
            await bot.send_message(chat_id=ADMIN_TELEGRAM_CHAT_ID, text=message)
        except telegram.error.TelegramError as e:
            print(f"L·ªói g·ª≠i th√¥ng b√°o admin: {e}")

async def main_job():
    """C√¥ng vi·ªác ch√≠nh."""
    job_start_time = datetime.now()
    print(f"B·∫ÆT ƒê·∫¶U: {job_start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    bot = await init_bot()
    if not bot:
        print("Kh√¥ng th·ªÉ kh·ªüi t·∫°o bot.")
        return

    await send_admin_notification(bot, f"üîÑ B·∫Øt ƒë·∫ßu: {job_start_time.strftime('%Y-%m-%d %H:%M:%S')}")

    try:
        # --- L·∫•y th√¥ng tin API key ---
        api_keys_info = []
        for api_key in DB_IP_API_KEYS:
            api_key_data = get_api_key_info(api_key)
            if api_key_data:
                api_keys_info.append(api_key_data)

        live_proxies_lists, live_proxies_count, failed_urls, proxy_info, country_counts = process_proxies()

        #Truy·ªÅn api_keys_info v√†o h√†m upload
        await upload_to_telegram(bot, live_proxies_lists, live_proxies_count, failed_urls, proxy_info, country_counts, api_keys_info)


        job_end_time = datetime.now()
        duration = job_end_time - job_start_time
        print(f"--- HO√ÄN TH√ÄNH: {job_end_time.strftime('%Y-%m-%d %H:%M:%S')}. Th·ªùi gian: {duration.total_seconds():.2f}s ---")
        await send_admin_notification(bot, f"‚úÖ Ho√†n th√†nh: {duration.total_seconds():.2f}s")


    except Exception as e:
        error_end_time = datetime.now()
        error_duration = error_end_time - job_start_time
        error_message = f"‚ùå L·ªñI: {error_end_time.strftime('%Y-%m-%d %H:%M:%S')}. Th·ªùi gian: {error_duration.total_seconds():.2f}s. L·ªói: {e}"
        print(error_message)
        await send_admin_notification(bot, error_message)

async def main():
    """H√†m main."""
    print(f"Ch·∫°y m·ªói {SCHEDULE_INTERVAL_MINUTES} ph√∫t. T·ªëi ƒëa {MAX_THREADS} lu·ªìng.")
    await main_job()  # Ch·∫°y ngay l·∫ßn ƒë·∫ßu
    schedule.every(SCHEDULE_INTERVAL_MINUTES).minutes.do(lambda: asyncio.create_task(main_job()))
    while True:
        schedule.run_pending()
        await asyncio.sleep(60)

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("D·ª´ng b·ªüi ng∆∞·ªùi d√πng.")
    except Exception as e:
        print(f"L·ªói: {e}")
